{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"65px\" src=\"https://upload.wikimedia.org/wikipedia/en/thumb/b/b1/Davivienda_logo.svg/1200px-Davivienda_logo.svg.png\" align=\"left\" hspace=\"10px\" width=\"20%\" vspace=\"15px\"></p>\n",
        "\n",
        "<h1 align=\"center\"> Prueba Técnica Profesional III Departamento de Datos no Estructurados  </h1>\n"
      ],
      "metadata": {
        "id": "nRAe41rkGhGc"
      },
      "id": "nRAe41rkGhGc"
    },
    {
      "cell_type": "markdown",
      "id": "418c8444",
      "metadata": {
        "id": "418c8444"
      },
      "source": [
        "<p style=»text-align: justify;»>\n",
        "El Departamento de Analítica No estructurada busca profesionales con fuertes capacidades técnicas y sobretodo una fuerte capacidad analítica. Por consiguiente esta prueba intenta poner a prueba la forma en la que plantea y soluciona problmeas. Es importante que presente el código que usa para resolver el problema con el único motivo de medir sus capacidades.\n",
        "\n",
        "Se recomienda que sea ordenado en su código y siga los lineamientos establecidos, aún así la prueba tiene un grado de flexibilidad. Se evaluará el orden y la creatividad a la hora de presentar la información. \n",
        "</p>\n",
        "\n",
        "\n",
        "**Nota** <br>\n",
        "Tenga en cuneta que éste ejercicio es hipotético y el banco no usará su trabajo más que para evaluar sus habiliadades para el cargo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objetivo**\n",
        "El objetivo de esta prueba es lograr un filtro que discrimine automáticamente un tipo de documento sin información relevante: páginas en blanco. Se busca que este filtro reciba como entrada una carpeta con imágenes de documentos diversos y produzca como salida dos carpetas, una con imágenes de páginas en blanco y otra con imágenes de páginas con contenido.\n",
        "\n",
        "Páginas con solo el membrete del documento se consideran páginas en blanco, así como las que, al momento de ser escaneadas, alcanzan a reflejar contenido ininteligible del reverso de la página."
      ],
      "metadata": {
        "id": "MRRXB1kbbvOz"
      },
      "id": "MRRXB1kbbvOz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación de Imágenes"
      ],
      "metadata": {
        "id": "QXEgCPkGbYIG"
      },
      "id": "QXEgCPkGbYIG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar el notebook en google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhQyt7zR-7XD",
        "outputId": "39414f4b-bac2-45f2-b2f3-3d81ecd22448"
      },
      "id": "QhQyt7zR-7XD",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías requeridas\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "7S7N-AIU4YQg"
      },
      "id": "7S7N-AIU4YQg",
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Importe las imágenes\n",
        "En la carpeta adjunta se encontrará con documentos tanto en blanco como con contenido. Su objetivo es generar un modelo que clasifique los elementos en \"Con Contenido\" y \"Sin Contenido\". Para eso puede utilizar reglas o modelos especificos."
      ],
      "metadata": {
        "id": "Cs3WaXmZG0uj"
      },
      "id": "Cs3WaXmZG0uj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la ruta y las categorias de los documentos\n",
        "dir = 'Prueba_conocimientos_davivienda/Ejercicio_1_Imagenes/Datasets'\n",
        "categories = ['Blanco', 'Documentos']"
      ],
      "metadata": {
        "id": "35uR8Il-AsIW"
      },
      "id": "35uR8Il-AsIW",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer paso es convertir las imágenes de documentos en blanco y con contenido en conjuntos de datos de entrenamiento y prueba. Para evitar imágenes con diferentes tamaños definimos el tamaño de cada imagen 50px50p. En este problema específico no necesitamos tener el cuenta el color en las imágenes para identificar si tienen contenido o no, por tanto podemos aplicar filtros de escala de grises para  trabajar con arreglos unidimensionales en lugar de tridimensionales (RGB)."
      ],
      "metadata": {
        "id": "E6UTyhnqF057"
      },
      "id": "E6UTyhnqF057"
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "img_size = (50, 50) # Definir el tamaño de las imágenes\n",
        "\n",
        "def create_training_data(): \n",
        "  for category in categories: # Categorías Blanco y Documentos\n",
        "    path = os.path.join(dir, category) # Crear ruta por categoría\n",
        "    class_num = categories.index(category) # Número de clases\n",
        "    for img in os.listdir(path):            # Iterar sobre cada imagen por categoria\n",
        "        try:\n",
        "          img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # Convertir en arreglo\n",
        "          new_array = cv2.resize(img_array, img_size) # Redimensionar imágenes\n",
        "          training_data.append([new_array, class_num]) # Añadir a training_data (img y clase)\n",
        "        except Exception as e: # Evitar errores en el conjunto de salida\n",
        "            pass\n",
        "\n",
        "create_training_data()"
      ],
      "metadata": {
        "id": "wuuqBCTKGtKU"
      },
      "id": "wuuqBCTKGtKU",
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Estructure la información\n",
        "Debido a que las imagenes son archivos separados lo primero que debe hacer es importarlas (recuerde que una imagen es esencialmente un arreglo de vectores), puede esturcturarlas a su gusto y marcar de ser necesario aquellas que va usar como test de pruebas. "
      ],
      "metadata": {
        "id": "ut1ODmgseSFj"
      },
      "id": "ut1ODmgseSFj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Deinir \"X\" con las características y \"y\" con las etiquetas\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "  X.append(features)\n",
        "  y.append(label)\n",
        "\n",
        "# Convertir en arreglos numpy\n",
        "X = np.array(X).reshape(-1, 50, 50, 1) # Redimensionar X\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "PJBIuJQpLEls"
      },
      "id": "PJBIuJQpLEls",
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el dataset en entrenamiento y prueba utilizando train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2, # 20% datos para prueba\n",
        "                                                    random_state=1,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "C95OhUcWWeiK"
      },
      "id": "C95OhUcWWeiK",
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a convertir el vector binario de las etiquetas en una matriz de valores binarios por clase"
      ],
      "metadata": {
        "id": "B3BXyRbKu8cd"
      },
      "id": "B3BXyRbKu8cd"
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2 # Definir número de clases\n",
        "# Convertir y_train en matriz de valores binarios\n",
        "y_train_binary = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "# Convertir y_test en matriz de valores binarios\n",
        "y_test_binary = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "sJcUIiMgdlek"
      },
      "id": "sJcUIiMgdlek",
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Describa su Estrategia de Análisis\n",
        "<p>Tiene libertad en la metodología para la clasificación. Aún así debe describir brevemente como realizará el análisis. Por ejemplo, si usará un modelo en donde requiera clasificar una cantidad pequeña de la data mencionelo o si planea condicionar la clasifiaciónes a reglas indique que reglas usará. Además si usa herramientas externas describalas y explique. </p>\n"
      ],
      "metadata": {
        "id": "SxK-QGJ1KeaY"
      },
      "id": "SxK-QGJ1KeaY"
    },
    {
      "cell_type": "code",
      "source": [
        "# IMportar los módulos necesarios para contruir el modelo (CNN)\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "metadata": {
        "id": "Ja9figXzbTNX"
      },
      "id": "Ja9figXzbTNX",
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El segundo paso es contruir el modelo, se procede a usar una red neuronal convolucional para clasificar las imágenes con y sin contenido. Las imágenes tienen un rango de píxeles de 0 a 255 por tanto se divide X entre 255 para normalizar.\n",
        "\n"
      ],
      "metadata": {
        "id": "w0lbDZjzwpNT"
      },
      "id": "w0lbDZjzwpNT"
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "238g-RuzOV6w"
      },
      "id": "238g-RuzOV6w",
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se compila el modelo con la función de pérdida \"binary crossentropy\", el optimizador \"adam\" y la métrica de monitoreo \"accuracy\"."
      ],
      "metadata": {
        "id": "33u2-4ptynJE"
      },
      "id": "33u2-4ptynJE"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VKnlL3oMOrLu"
      },
      "id": "VKnlL3oMOrLu",
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se entrena el modelo con los datos de entrenamiento, se define el tamaño del lote con el que se va a alimentar la red en cada iteración y se definen 5 iteraciones asignando un 10% de los datos a la validación del modelo."
      ],
      "metadata": {
        "id": "3cpGQweQzVOs"
      },
      "id": "3cpGQweQzVOs"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train_binary, batch_size=32, epochs=5, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjAVVRUSOtjd",
        "outputId": "c07d9a56-9eac-47ec-a640-b1612324fa7f"
      },
      "id": "AjAVVRUSOtjd",
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 8s 1s/step - loss: 334.4733 - accuracy: 0.4237 - val_loss: 10.2962 - val_accuracy: 0.8000\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 9s 1s/step - loss: 16.4599 - accuracy: 0.7684 - val_loss: 7.4392 - val_accuracy: 0.9000\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 2.6006 - accuracy: 0.9266 - val_loss: 3.1890 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.5908 - accuracy: 0.9944 - val_loss: 3.6665 - val_accuracy: 0.9000\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.9145 - accuracy: 0.9661 - val_loss: 0.0807 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc806a0a050>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Interpretación de Reusultados\n",
        "<p>Al final tiene que presentar la información en una matriz que muestre la calidad de su clasificación y evaluarla con la medida que guste. </p>\n",
        "<br>\n",
        "<img src=\"https://www.ecured.cu/images/3/31/Matrices_de_confusi%C3%B3n.png\" >"
      ],
      "metadata": {
        "id": "8Dp_gy0lEfDZ"
      },
      "id": "8Dp_gy0lEfDZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "qvr999F9bu39"
      },
      "id": "qvr999F9bu39",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos la matriz de confusión\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(np.argmax(y_test_binary, axis=1), np.argmax(y_pred, axis=1))\n",
        "\n",
        "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-6DtdvVyfhJP",
        "outputId": "a5ef6d38-03f6-41ec-a3a3-47b89a0460ef"
      },
      "id": "-6DtdvVyfhJP",
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc8944afdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos el reporte de las métricas de evaluación\n",
        "report = classification_report(np.argmax(y_test_binary, axis=1), np.argmax(y_pred, axis=1))\n",
        "print(report, sep = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5wu6NkIfH7z",
        "outputId": "bf7fc5f5-8afb-4952-ad16-87e11fad7d51"
      },
      "id": "J5wu6NkIfH7z",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Prueba_de_conocimientos_I_DNE_Davivienda.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}